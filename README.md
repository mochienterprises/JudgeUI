# JudgeUI - AI Judge Evaluation Framework

**A web-based and CLI framework for testing AI models' ability to evaluate argument quality.**

Built for scientific testing of AI judges across multiple models, with fault injection, real-world corpus integration, and political bias measurement.

---

## ğŸ†• What's New in This Branch

### **Web UI (NEW!)**
Complete Flask-based web interface providing:
- **Interactive Argument Generation** - Select topics, inject faults, generate instantly
- **Custom Text Evaluation** - Paste any argument and evaluate it with multiple AI judges
- **CMV Corpus Explorer** - Browse and sample from 293k real Reddit arguments
- **Political Compass Testing** - Visual, interactive bias measurement with real-time charts
- **Results Dashboard** - Browse all arguments, experiments, and evaluations

**No command line required!** Access everything at http://localhost:5000

---

## What It Does

JudgeUI helps you answer questions like:
- Can Claude detect logical fallacies better than GPT-4?
- Does this AI model have political bias?
- Can AI judges identify genuinely persuasive arguments?
- How do different system prompts affect evaluation quality?

**Core Features:**
- ğŸŒ **Web UI** - Interactive interface for generation and evaluation *(NEW!)*
- ğŸ§ª **Fault Injection** - Test with arguments containing known flaws
- ğŸ“Š **Multi-Model Testing** - Compare Claude, GPT, Gemini side-by-side
- ğŸ—³ï¸ **Political Compass** - Measure model bias scientifically
- ğŸ’¬ **Real Arguments** - 293k arguments from Reddit's ChangeMyView

---

## Quick Start

### Installation

```bash
# Clone and install
git clone https://github.com/mochienterprises/JudgeUI.git
cd JudgeUI
pip install -r requirements.txt

# Set up API keys
cp .env.example .env
# Edit .env with your keys (at minimum: ANTHROPIC_API_KEY)
```

### Web UI (Recommended)

```bash
# Install Flask
pip install flask

# Run the web interface
python app.py

# Open http://localhost:5000
```

**Web UI Features:**
- Generate arguments with controlled faults
- Evaluate any text (paste your own arguments)
- Explore 293k CMV arguments
- Run Political Compass tests
- Visual results and comparisons

---

## ğŸ”„ What's Different from Main Branch

| Feature | Main Branch (CLI Only) | This Branch (+ Web UI) |
|---------|----------------------|------------------------|
| Generate Arguments | âœ… Command line only | âœ… **Interactive web form** |
| Evaluate Arguments | âœ… Existing args only | âœ… **+ Paste custom text** |
| Political Compass | âœ… CLI results as JSON | âœ… **+ Visual chart & history** |
| CMV Corpus | âœ… Sample via CLI | âœ… **+ Browse & explore UI** |
| User Experience | Terminal-based | **Web-based + Terminal** |
| Setup Required | Python + CLI knowledge | **Just open browser** |

**Key Improvements:**
- Zero barrier to entry (no CLI needed)
- Visual feedback and results
- Real-time argument evaluation
- Interactive corpus exploration
- Professional demo-ready interface

---

## ğŸ¨ Web UI Overview (NEW!)

The web interface provides a complete, user-friendly alternative to the CLI tools:

### **Pages:**

#### 1. Generate Arguments (`/generate`)
- Select from 40+ curated debate topics or enter custom topics
- Choose stance (for/against)
- Select which logical fallacies to inject (19 types available)
- Choose AI model for generation
- Instantly generate and preview arguments
- Direct link to evaluate generated arguments

#### 2. Evaluate Arguments (`/evaluate`)
**Two modes:**
- **Existing Arguments** - Browse and evaluate previously generated arguments
- **Custom Text** â­ - Paste ANY text and get instant evaluation

**Features:**
- Multiple judge models (Claude, GPT, Gemini)
- Adjustable temperature and evaluator prompts
- Real-time score (0-100)
- Detected faults with descriptions
- Ground truth comparison for generated arguments
- Judge's reasoning displayed

#### 3. CMV Corpus Explorer (`/cmv`)
- View corpus statistics (293k utterances, 3k conversations)
- Sample random argument pairs
- Compare winning vs losing arguments
- Full text viewing with modal

#### 4. Political Compass Testing (`/political-compass`)
- Run the full 62-question Political Compass test on any model
- Test baseline position or bias-manipulated positions
- Visual compass chart showing results
- Economic (-10 to +10) and Social (-10 to +10) axes
- View all 62 question responses
- Test history to compare multiple runs

#### 5. Browse (`/browse`)
- Table view of all generated arguments
- Filter by topic, stance, source
- Quick access to evaluate any argument

---

## Command Line (Advanced Users)

For batch processing and experiments, use the CLI tools:

```bash
# Generate an argument with specific faults
python generate_arguments.py --topic "Universal healthcare" --stance for --faults strawman cherry_picking

# Evaluate it with Claude
python run_experiment.py experiments/quick-test.yaml

# Test political bias
python run_political_compass.py --models claude-sonnet-4-5

# CMV persuasion detection
python run_cmv_experiment.py --pairs 20 --models claude-sonnet-4-5
```

---

## Architecture

```
Web UI (Flask)
    â†“
Core Framework (Python)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Generator  â”‚  Evaluator   â”‚  Analysis  â”‚
â”‚  - Topics   â”‚  - Blind     â”‚  - Scores  â”‚
â”‚  - Faults   â”‚  - Multi-    â”‚  - Bias    â”‚
â”‚  - Stances  â”‚    model     â”‚  - Faults  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“               â†“              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM Providers                          â”‚
â”‚  Anthropic â€¢ OpenAI â€¢ Google â€¢ xAI      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Components:**
- `app.py` - Web interface
- `src/generator.py` - Argument generation with fault injection
- `src/evaluator.py` - Blind evaluation system
- `src/convokit_loader.py` - CMV corpus integration
- `config/` - Models, faults, topics, prompts

---

## Project Structure

```
JudgeUI/
â”œâ”€â”€ app.py                    # ğŸ†• Web UI (Flask)
â”œâ”€â”€ templates/                # ğŸ†• Web UI templates
â”‚   â”œâ”€â”€ base.html             #     Shared layout
â”‚   â”œâ”€â”€ index.html            #     Homepage
â”‚   â”œâ”€â”€ generate.html         #     Argument generation
â”‚   â”œâ”€â”€ evaluate.html         #     Evaluation (existing + custom text)
â”‚   â”œâ”€â”€ cmv.html              #     CMV corpus explorer
â”‚   â”œâ”€â”€ browse.html           #     Argument browser
â”‚   â””â”€â”€ political_compass.html#     Political Compass testing
â”œâ”€â”€ src/                      # Core framework
â”‚   â”œâ”€â”€ providers/            # LLM integrations
â”‚   â”œâ”€â”€ generator.py          # Argument generation
â”‚   â”œâ”€â”€ evaluator.py          # Evaluation engine
â”‚   â”œâ”€â”€ experiment.py         # Batch experiments
â”‚   â”œâ”€â”€ convokit_loader.py    # CMV corpus
â”‚   â””â”€â”€ analysis.py           # Results analysis
â”œâ”€â”€ config/                   # Configuration
â”‚   â”œâ”€â”€ models.yaml           # Model registry
â”‚   â”œâ”€â”€ faults.yaml           # 19 fault types
â”‚   â”œâ”€â”€ topics.yaml           # 40+ debate topics
â”‚   â””â”€â”€ prompts/              # System prompts
â”œâ”€â”€ run_*.py                  # CLI tools
â””â”€â”€ results/                  # Output data
```

---

## Configuration

### Supported Models

**Anthropic:** Claude Sonnet 4.5, Claude 4 Opus  
**OpenAI:** GPT-4o, GPT-5.2, o1  
**Google:** Gemini 2.0 Flash, Gemini 2.5 Flash/Pro  
**xAI:** Grok-2, Grok-3

### Fault Types (19 total)

**Logical Fallacies:** strawman, circular_reasoning, false_dichotomy, false_cause, hasty_generalization, non_sequitur, slippery_slope

**Intellectual Dishonesty:** ad_hominem, red_herring, moving_goalposts, cherry_picking, gaslighting

**Structural Failures:** no_evidence, contradictory_claims, unsupported_conclusion, poor_cohesion

Each fault has a severity score (-10 to -15 points) used for ground truth calculation.

### Topics

40+ curated debate topics across categories:
- Political (gun control, immigration, UBI)
- Economic (minimum wage, wealth tax, free trade)
- Social (death penalty, drug legalization, prison reform)
- Technology (AI regulation, data privacy, autonomous vehicles)
- Environmental (carbon tax, nuclear energy, geoengineering)
- Healthcare (universal healthcare, vaccine mandates, drug pricing)
- Education (free college, school choice, standardized testing)

---

## Example Workflows

### Web UI: Evaluate Custom Text

1. Go to http://localhost:5000/evaluate
2. Click "Custom Text" tab
3. Paste any argument
4. Select judge model (Claude, GPT, etc.)
5. Get instant score + detected faults

### CLI: Generate & Test Arguments

```bash
# Generate argument with known faults
python generate_arguments.py \
  --topic gun-control \
  --stance for \
  --faults strawman ad_hominem \
  --model claude-sonnet-4-5

# Run evaluation experiment
python run_experiment.py experiments/quick-test.yaml

# Analyze results
python analyze.py <experiment_id>
```

### Political Bias Testing

```bash
# Measure baseline position
python run_political_compass.py --models claude-sonnet-4-5 gpt-4o

# Test bias manipulation
python run_political_compass.py \
  --models claude-sonnet-4-5 \
  --bias baseline auth_left auth_right lib_left lib_right

# Results show Economic (-10 to +10) and Social (-10 to +10) scores
```

---

## API Keys

Required in `.env`:

```bash
ANTHROPIC_API_KEY=sk-ant-...     # For Claude models
OPENAI_API_KEY=sk-...            # For GPT models
GEMINI_API_KEY=AIza...           # For Gemini models
GROK_API_KEY=xai-...             # For Grok models
```

You only need keys for models you want to test.

---

## Results & Data

**Experiments:** Saved as JSON in `results/experiments/`  
**CMV Tests:** Saved in `results/cmv/`  
**Political Compass:** Saved in `results/political_compass/`  
**Arguments:** Stored in `arguments/generated/`, `arguments/curated/`

Each result includes:
- Model configurations
- Evaluation scores
- Detected faults
- Ground truth comparisons (when applicable)
- Timestamps and metadata

---

## Current Development Status

### âœ… Working
- **ğŸ†• Web UI for generation and evaluation** - Complete Flask interface with 5 pages
- **ğŸ†• Custom text evaluation** - Paste any argument for instant evaluation
- **ğŸ†• Interactive Political Compass testing** - Visual charts and real-time results
- Multi-provider LLM support (4 providers, 10+ models)
- Fault injection system (19 fault types)
- CMV corpus integration (293k arguments)
- Political Compass testing (62 questions)
- Parallel experiment execution
- CLI tools for batch processing

### ğŸš§ In Progress
- Results visualization/dashboards (charts, graphs)
- Additional corpora (debate.org, persuasion-reddit)
- Advanced statistical analysis
- Deployment guides

### ğŸ“‹ Planned
- Team collaboration features
- A/B testing framework
- Custom fault definitions via UI
- Real-time experiment monitoring

---

## Branch Information

**Main updates in this branch:**
- Complete web UI implementation (`app.py` + templates)
- Custom text evaluation capability
- Interactive Political Compass testing with visualizations
- CMV corpus explorer with sampling
- Improved user experience for all core features

**Based on:** Framework updates including Political Compass integration, CMV corpus support, and multi-provider architecture

---

## Contributing

**Areas of interest:**
- New LLM provider integrations
- Additional argument corpora
- Improved fault taxonomy
- Evaluation prompt engineering
- Visualization/analysis tools

---

## Citation

If you use JudgeUI in research, please cite:

```
JudgeUI: A Framework for Testing AI Judge Algorithms
https://github.com/mochienterprises/JudgeUI
```

---

## License

MIT License - See LICENSE file for details

---

## Acknowledgments

- **ConvoKit** - For the ChangeMyView corpus
- **Political Compass** - For the 62-question test framework
- Built with Flask, Anthropic API, OpenAI API, Google AI API
